To run this version, you need the file llama-2-7b-chat.Q8_0.gguf downloaded from [HuggingFace/TheBloke](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF) in this folder.

This version will run the app using the streamlit inside a Docker container.
